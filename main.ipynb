{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kerol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kerol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kerol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\kerol\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = 'dataset/cleaned_data.csv'\n",
    "TEST_DATA_PATH = 'dataset/test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Expensive Junk: This product consists of a pie...</td>\n",
       "      <td>expensive junk product consists piece thin fle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Toast too dark: Even on the lowest setting, th...</td>\n",
       "      <td>toast too dark even lowest setting toast too d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Excellent imagery...dumbed down story: I enjoy...</td>\n",
       "      <td>excellent imagerydumbed story enjoyed disc vid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Are we pretending everyone is married?: The au...</td>\n",
       "      <td>pretending everyone married author pretend par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Not worth your time: Might as well just use a ...</td>\n",
       "      <td>not worth time might well use knife product ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>2</td>\n",
       "      <td>All Clad Pizza Cutter: The best pizza cutter I...</td>\n",
       "      <td>clad pizza cutter best pizza cutter ever used ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>1</td>\n",
       "      <td>MEH...: Its ok. i dont hate it. i have a short...</td>\n",
       "      <td>meh ok dont hate short torso look really big r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>2</td>\n",
       "      <td>Is what it is: This connector cable is easy to...</td>\n",
       "      <td>connector cable easy use work intended im not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>1</td>\n",
       "      <td>Sorry--I'm not getting it: Just read this afte...</td>\n",
       "      <td>sorryim not getting read several friend raved ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>1</td>\n",
       "      <td>Comedy vs. Code: I appreciate the attempt to i...</td>\n",
       "      <td>comedy v code appreciate attempt inject comedy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                               text  \\\n",
       "0           1  Expensive Junk: This product consists of a pie...   \n",
       "1           1  Toast too dark: Even on the lowest setting, th...   \n",
       "2           2  Excellent imagery...dumbed down story: I enjoy...   \n",
       "3           1  Are we pretending everyone is married?: The au...   \n",
       "4           1  Not worth your time: Might as well just use a ...   \n",
       "...       ...                                                ...   \n",
       "999995      2  All Clad Pizza Cutter: The best pizza cutter I...   \n",
       "999996      1  MEH...: Its ok. i dont hate it. i have a short...   \n",
       "999997      2  Is what it is: This connector cable is easy to...   \n",
       "999998      1  Sorry--I'm not getting it: Just read this afte...   \n",
       "999999      1  Comedy vs. Code: I appreciate the attempt to i...   \n",
       "\n",
       "                                             cleaned_text  \n",
       "0       expensive junk product consists piece thin fle...  \n",
       "1       toast too dark even lowest setting toast too d...  \n",
       "2       excellent imagerydumbed story enjoyed disc vid...  \n",
       "3       pretending everyone married author pretend par...  \n",
       "4       not worth time might well use knife product ho...  \n",
       "...                                                   ...  \n",
       "999995  clad pizza cutter best pizza cutter ever used ...  \n",
       "999996  meh ok dont hate short torso look really big r...  \n",
       "999997  connector cable easy use work intended im not ...  \n",
       "999998  sorryim not getting read several friend raved ...  \n",
       "999999  comedy v code appreciate attempt inject comedy...  \n",
       "\n",
       "[1000000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(TRAIN_DATA_PATH)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kerol\\AppData\\Local\\Temp\\ipykernel_33768\\2909357514.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df['label'].replace({1:0, 2:1},inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train_df['label'].replace({1:0, 2:1},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Expensive Junk: This product consists of a pie...</td>\n",
       "      <td>expensive junk product consists piece thin fle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Toast too dark: Even on the lowest setting, th...</td>\n",
       "      <td>toast too dark even lowest setting toast too d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Excellent imagery...dumbed down story: I enjoy...</td>\n",
       "      <td>excellent imagerydumbed story enjoyed disc vid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Are we pretending everyone is married?: The au...</td>\n",
       "      <td>pretending everyone married author pretend par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Not worth your time: Might as well just use a ...</td>\n",
       "      <td>not worth time might well use knife product ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>1</td>\n",
       "      <td>All Clad Pizza Cutter: The best pizza cutter I...</td>\n",
       "      <td>clad pizza cutter best pizza cutter ever used ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>0</td>\n",
       "      <td>MEH...: Its ok. i dont hate it. i have a short...</td>\n",
       "      <td>meh ok dont hate short torso look really big r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>1</td>\n",
       "      <td>Is what it is: This connector cable is easy to...</td>\n",
       "      <td>connector cable easy use work intended im not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>0</td>\n",
       "      <td>Sorry--I'm not getting it: Just read this afte...</td>\n",
       "      <td>sorryim not getting read several friend raved ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0</td>\n",
       "      <td>Comedy vs. Code: I appreciate the attempt to i...</td>\n",
       "      <td>comedy v code appreciate attempt inject comedy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                               text  \\\n",
       "0           0  Expensive Junk: This product consists of a pie...   \n",
       "1           0  Toast too dark: Even on the lowest setting, th...   \n",
       "2           1  Excellent imagery...dumbed down story: I enjoy...   \n",
       "3           0  Are we pretending everyone is married?: The au...   \n",
       "4           0  Not worth your time: Might as well just use a ...   \n",
       "...       ...                                                ...   \n",
       "999995      1  All Clad Pizza Cutter: The best pizza cutter I...   \n",
       "999996      0  MEH...: Its ok. i dont hate it. i have a short...   \n",
       "999997      1  Is what it is: This connector cable is easy to...   \n",
       "999998      0  Sorry--I'm not getting it: Just read this afte...   \n",
       "999999      0  Comedy vs. Code: I appreciate the attempt to i...   \n",
       "\n",
       "                                             cleaned_text  \n",
       "0       expensive junk product consists piece thin fle...  \n",
       "1       toast too dark even lowest setting toast too d...  \n",
       "2       excellent imagerydumbed story enjoyed disc vid...  \n",
       "3       pretending everyone married author pretend par...  \n",
       "4       not worth time might well use knife product ho...  \n",
       "...                                                   ...  \n",
       "999995  clad pizza cutter best pizza cutter ever used ...  \n",
       "999996  meh ok dont hate short torso look really big r...  \n",
       "999997  connector cable easy use work intended im not ...  \n",
       "999998  sorryim not getting read several friend raved ...  \n",
       "999999  comedy v code appreciate attempt inject comedy...  \n",
       "\n",
       "[1000000 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2    500024\n",
       "1    499976\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Removing Tags\n",
    "    text = re.sub('#\\S+', '', text).strip()\n",
    "\n",
    "    # Removing Mentions\n",
    "    text = re.sub('@\\S+', '', text).strip()\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # words like \"not\", \"no\", \"very\", \"but\", and \"never\" can play a crucial role in determining the sentiment\n",
    "    words_to_remove = [\"not\", \"no\", \"never\", \"neither\", \"nor\", \"very\", \n",
    "                   \"really\", \"too\", \"extremely\", \"quite\", \"but\", \"however\", \n",
    "                   \"although\", \"though\", \"if\", \"unless\", \"except\"]\n",
    "\n",
    "    stop_words = [word for word in stop_words if word not in words_to_remove]\n",
    "\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Join tokens back into text\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    cleaned_text = ' '.join(cleaned_text.split())\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['cleaned_text'] = train_df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Tokenize reviews\n",
    "tokenized_reviews = [review.split() for review in train_df['cleaned_text'].iloc[:50000]]\n",
    "word2vec_model = Word2Vec(sentences=tokenized_reviews, vector_size=100, window=5, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Tokenize with Keras\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_df['cleaned_text'].iloc[:50000])\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Create embedding matrix\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec_model.wv:\n",
    "        embedding_matrix[i] = word2vec_model.wv[word]\n",
    "    else:\n",
    "        embedding_matrix[i] = np.random.normal(scale=0.6, size=(embedding_dim,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(train_df['cleaned_text'].iloc[:50000])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=100, padding='post')\n",
    "labels = np.array(train_df['label'].iloc[:50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kerol\\anaconda3\\envs\\gp\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(\n",
    "    input_dim=len(word_index) + 1,\n",
    "    output_dim=embedding_dim,\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=100,\n",
    "    trainable=False  # Set to True if fine-tune\n",
    "))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 22ms/step - accuracy: 0.5163 - loss: 0.6906 - val_accuracy: 0.5123 - val_loss: 0.6928\n",
      "Epoch 2/5\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 22ms/step - accuracy: 0.5350 - loss: 0.6824 - val_accuracy: 0.8530 - val_loss: 0.3517\n",
      "Epoch 3/5\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - accuracy: 0.8661 - loss: 0.3160 - val_accuracy: 0.8796 - val_loss: 0.2861\n",
      "Epoch 4/5\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 27ms/step - accuracy: 0.8901 - loss: 0.2686 - val_accuracy: 0.8863 - val_loss: 0.2750\n",
      "Epoch 5/5\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.9003 - loss: 0.2495 - val_accuracy: 0.8737 - val_loss: 0.2972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1df05e1f610>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and pad new review\n",
    "text = \"this product is amazing\"\n",
    "\n",
    "new_text = [clean_text(text)]\n",
    "seq = tokenizer.texts_to_sequences(new_text)\n",
    "padded = pad_sequences(seq, maxlen=100, padding='post')\n",
    "\n",
    "# Predict\n",
    "pred = model.predict(padded)\n",
    "print(\"Positive\" if pred[0][0] > 0.5 else \"Negative\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
